# synthetic-data

**In this 2-week course you’ll learn to generate high‑quality synthetic datasets for fine‑tuning AI models using LLMs.**  
- **Week 1 – Supervised Fine‑Tuning:** Compare open‑ vs. closed‑source models, craft prompt templates and pipelines, build a distilabel SFT dataset, then explore and filter it to improve data quality.  
- **Week 2 – Preference Fine‑Tuning:** Master preference‑tuning fundamentals, experiment with specialized prompt templates (including insights from the UltraFeedback paper), and assemble a distilabel preference dataset with rigorous analysis and filtering.  

This course provides you with end‑to‑end expertise in prompt engineering, model selection, and data‑quality evaluation—enabling you to reduce manual labeling efforts, speed up development cycles, and deploy scalable fine‑tuning workflows across research and industry projects.  
